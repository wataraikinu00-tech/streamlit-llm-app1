import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
import os

from dotenv import load_dotenv

load_dotenv()



# =========================================
# API ã‚­ãƒ¼ã®ç¢ºèª
# =========================================
def check_api_key():
    # Streamlit Cloud ã® Secrets å„ªå…ˆ
    api_key = st.secrets.get("OPENAI_API_KEY", None)

    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ (.env) ã«ã‚‚å¯¾å¿œ
    if api_key is None:
        api_key = os.getenv("OPENAI_API_KEY", None)

    return api_key


# =========================================
# LLM å¿œç­”ç”¨ã®é–¢æ•°
# =========================================
def get_llm_response(user_text: str, expert: str, chat_history):
    """
    user_text: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
    expert: å°‚é–€å®¶ã®ç¨®é¡
    chat_history: Streamlit ã® session_state["history"]
    """

    expert_prompts = {
        "æ³•å¾‹": "ã‚ãªãŸã¯å„ªç§€ãªæ³•å¾‹å°‚é–€å®¶ã§ã™ã€‚æ³•å¾‹ã®è¦³ç‚¹ã‹ã‚‰ã€æ­£ç¢ºã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "ã‚¹ãƒãƒ¼ãƒ„": "ã‚ãªãŸã¯ã‚¹ãƒãƒ¼ãƒ„ç§‘å­¦ã®å°‚é–€å®¶ã§ã™ã€‚é‹å‹•ç”Ÿç†å­¦ã‚„ã‚¹ãƒãƒ¼ãƒ„ç†è«–ã‚’è¸ã¾ãˆã¦ç­”ãˆã¦ãã ã•ã„ã€‚",
        "æ „é¤Šå­¦": "ã‚ãªãŸã¯æ „é¤Šå­¦ã®å°‚é–€å®¶ã§ã™ã€‚é£Ÿäº‹ãƒ»æ „é¤Šã®è¦³ç‚¹ã‹ã‚‰ç§‘å­¦çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
        "åŒ»å­¦": "ã‚ãªãŸã¯åŒ»å¸«ã§ã™ã€‚åŒ»å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ã¦å°‚é–€çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
        "å¿ƒç†å­¦": "ã‚ãªãŸã¯å¿ƒç†å­¦è€…ã§ã™ã€‚å¿ƒç†å­¦ç†è«–ã«åŸºã¥ã„ã¦åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "IT": "ã‚ãªãŸã¯ITã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚æŠ€è¡“çš„ãªè¦–ç‚¹ã§ä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
    }

    api_key = check_api_key()
    if api_key is None:
        return "âŒ **API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚**\n\nStreamlit Cloud ã® Secrets ã¾ãŸã¯ `.env` ã« `OPENAI_API_KEY` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.5,
        api_key=api_key
    )

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    messages = [SystemMessage(content=expert_prompts[expert])]
    messages.extend(chat_history)  # é€£ç¶šä¼šè©±ã®å±¥æ­´
    messages.append(HumanMessage(content=user_text))

    # LLM å¿œç­”
    response = llm.invoke(messages)

    return response.content


# =========================================
# Streamlit UI
# =========================================
st.set_page_config(page_title="AI ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª", page_icon="ğŸ¤–")
st.title("ğŸ¤– LangChain Ã— Streamlit é€£ç¶šãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª")
st.write("å°‚é–€å®¶ã‚’é¸ã³ã€è³ªå•ã™ã‚‹ã¨ AI ãŒãã®å°‚é–€å®¶ã¨ã—ã¦å›ç­”ã—ã¾ã™ã€‚")


# =========================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆï¼ˆå±¥æ­´ï¼‰
# =========================================
if "history" not in st.session_state:
    st.session_state["history"] = []  # System / Human / AI ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸


# =========================================
# UIï¼šå°‚é–€å®¶é¸æŠ
# =========================================
expert = st.selectbox(
    "AI ã«ã©ã®å°‚é–€å®¶ã¨ã—ã¦å›ç­”ã•ã›ã¾ã™ã‹ï¼Ÿ",
    ["æ³•å¾‹", "ã‚¹ãƒãƒ¼ãƒ„", "æ „é¤Šå­¦", "åŒ»å­¦", "å¿ƒç†å­¦", "IT"]
)

st.write("---")

# =========================================
# UIï¼šå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
# =========================================
user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", height=120)

if st.button("é€ä¿¡"):
    if user_input.strip() == "":
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™ã€‚å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
            ai_response = get_llm_response(
                user_input,
                expert,
                st.session_state["history"]
            )

            # å±¥æ­´ã«è¿½åŠ ï¼ˆé€£ç¶šãƒãƒ£ãƒƒãƒˆï¼‰
            st.session_state["history"].append(HumanMessage(content=user_input))
            st.session_state["history"].append(AIMessage(content=ai_response))


st.write("---")
st.subheader("ğŸ“œ å›ç­”å±¥æ­´")

# =========================================
# å±¥æ­´è¡¨ç¤º
# =========================================
for msg in st.session_state["history"]:
    if isinstance(msg, HumanMessage):
        st.markdown(f"**ğŸ§‘â€ğŸ’¬ ã‚ãªãŸ:** {msg.content}")
    elif isinstance(msg, AIMessage):
        st.markdown(f"**ğŸ¤– AI ({expert}):** {msg.content}")
    st.write("---")


# =========================================
# ãƒ•ãƒƒã‚¿ãƒ¼
# =========================================
st.caption("Powered by Streamlit Ã— LangChain Ã— OpenAI")


